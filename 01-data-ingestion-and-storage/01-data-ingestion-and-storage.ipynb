{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0898df54",
   "metadata": {},
   "source": [
    "# #01 Data Ingestion and Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d0dc1a",
   "metadata": {},
   "source": [
    "### 1. Types of Data\n",
    "\n",
    "| Type                | Description                                        | Examples                       |\n",
    "| ------------------- | -------------------------------------------------- | ------------------------------ |\n",
    "| **Structured**      | Organized with a fixed schema; easy to query.      | SQL tables, CSV, Excel         |\n",
    "| **Unstructured**    | No predefined structure; harder to query directly. | Images, videos, PDFs, emails   |\n",
    "| **Semi-Structured** | Has partial structure (metadata, tags).            | JSON, XML, logs, email headers |\n",
    "\n",
    "\n",
    "### 2. The 3 V’s of Data\n",
    "\n",
    "| Property     | Meaning                                          | Example                         |\n",
    "| ------------ | ------------------------------------------------ | ------------------------------- |\n",
    "| **Volume**   | Size of the data.                                | Terabytes of social media data. |\n",
    "| **Velocity** | Speed at which data arrives & must be processed. | IoT sensor data stream.         |\n",
    "| **Variety**  | Different types & formats of data.               | DB records + logs + images.     |\n",
    "\n",
    "\n",
    "### 3. Data Warehouse vs Data Lake\n",
    "\n",
    "| Feature   | **Data Warehouse**               | **Data Lake**                         |\n",
    "| --------- | -------------------------------- | ------------------------------------- |\n",
    "| Data Type | Structured                       | All data types                        |\n",
    "| Schema    | **Schema-on-write** (predefined) | **Schema-on-read** (decide later)     |\n",
    "| Workflow  | **ETL** (clean before load)      | **ELT** (load first, transform later) |\n",
    "| Use Case  | BI dashboards, analytics         | ML, scalable storage, exploration     |\n",
    "| Examples  | Amazon **Redshift**, BigQuery    | Amazon **S3**, ADLS, HDFS             |\n",
    "\n",
    "**When to Use Which**\n",
    "\n",
    "- Data Warehouse → When data is structured and used mainly for analytics & reporting.\n",
    "\n",
    "- Data Lake → When data is raw, large-scale, used for ML, discovery, or unstructured storage.\n",
    "\n",
    "- Most real-world systems use both (Lake → Warehouse).\n",
    "\n",
    "### 4. Data Lakehouse\n",
    "\n",
    "A hybrid architecture combining:\n",
    "\n",
    "- Flexibility of Data Lake\n",
    "\n",
    "- Performance & reliability of Warehouse\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "- Databricks Lakehouse\n",
    "\n",
    "- Delta Lake\n",
    "\n",
    "- AWS Lake Formation\n",
    "\n",
    "### 5. Data Mesh\n",
    "\n",
    "More about organization & ownership, not tools:\n",
    "\n",
    "- Each team owns its data as a product (domain-oriented).\n",
    "\n",
    "- Federated governance.\n",
    "\n",
    "- Supports self-service data consumption.\n",
    "\n",
    "### 6. ETL Pipelines\n",
    "\n",
    "| Step          | Purpose                                           |\n",
    "| ------------- | ------------------------------------------------- |\n",
    "| **Extract**   | Pull data from source systems (DBs, APIs, files). |\n",
    "| **Transform** | Clean, normalize, aggregate, format data.         |\n",
    "| **Load**      | Store data in warehouse (batch or streaming).     |\n",
    "\n",
    "**Common AWS tools:**\n",
    "\n",
    "- AWS Glue, Lambda, Step Functions, Airflow (MWAA), EventBridge.\n",
    "\n",
    "### 7. Data File Formats\n",
    "\n",
    "| Format      | Type                             | Best Use                                             |\n",
    "| ----------- | -------------------------------- | ---------------------------------------------------- |\n",
    "| **CSV**     | Text, structured                 | Simple tabular data, export/import.                  |\n",
    "| **JSON**    | Semi-structured                  | API data, nested data.                               |\n",
    "| **Avro**    | Binary + schema stored with data | Streaming & schema evolution (Kafka).                |\n",
    "| **Parquet** | **Columnar** format              | Analytics & big data (Spark/Hive/Redshift Spectrum). |\n",
    "\n",
    "## Amazon S3\n",
    "\n",
    "### 8. Amazon S3 Overview\n",
    "\n",
    "- Object storage (virtually infinite storage).\n",
    "\n",
    "- Stores files as objects inside buckets.\n",
    "\n",
    "- No real folders — key names simulate folder paths.\n",
    "\n",
    "#### Security\n",
    "\n",
    "- IAM policies (user-based)\n",
    "\n",
    "- Bucket policies (resource-based)\n",
    "\n",
    "- ACLs (legacy / avoid)\n",
    "\n",
    "#### Versioning\n",
    "\n",
    "- Keeps history of changes and restores deleted objects.\n",
    "\n",
    "#### 9. S3 Storage Classes\n",
    "\n",
    "| Class                | Best For                         | Retrieval | Cost                      |\n",
    "| -------------------- | -------------------------------- | --------- | ------------------------- |\n",
    "| Standard             | Frequent access                  | Instant   | $$                        |\n",
    "| Standard-IA          | Infrequent access                | Instant   | $                         |\n",
    "| One Zone-IA          | Non-critical backups             | Instant   | $ (cheaper but single AZ) |\n",
    "| Glacier Instant      | Rare access but need quick reads | ms        | $                         |\n",
    "| Glacier Flexible     | Archival (hrs to retrieve)       | 1–12 hrs  | $$ low                    |\n",
    "| Glacier Deep Archive | Long-term cold archive           | 12–48 hrs | ***lowest***              |\n",
    "\n",
    "#### S3 Intelligent-Tiering\n",
    "\n",
    "- Automatically moves objects to cheaper tiers based on access frequency.\n",
    "\n",
    "## Elastic Block Store (EBS)\n",
    "\n",
    "## Elastic F Store (EFS)\n",
    "\n",
    "## Amazon FSx\n",
    "\n",
    "## Amazon Kinesis Data Streams"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
